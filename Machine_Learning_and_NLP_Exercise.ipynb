{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning and NLP Exercises #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the same review data set from Kaggle from Week 2 for this exercise. The product we'll focus on this time is a cappuccino cup. The goal of this week is to not only preprocess the data, but to classify reviews as positive or negative based on the review text.\n",
    "\n",
    "The following code will help you load in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2XP9IN4JOMROD</td>\n",
       "      <td>1</td>\n",
       "      <td>I wanted to love this. I was even prepared for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2TS09JCXNV1VD</td>\n",
       "      <td>5</td>\n",
       "      <td>Grove Square Cappuccino Cups were excellent. T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AJ3L5J7GN09SV</td>\n",
       "      <td>2</td>\n",
       "      <td>I bought the Grove Square hazelnut cappuccino ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A3CZD34ZTUJME7</td>\n",
       "      <td>1</td>\n",
       "      <td>I love my Keurig, and I love most of the Keuri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AWKN396SHAQGP</td>\n",
       "      <td>1</td>\n",
       "      <td>It's a powdered drink. No filter in k-cup.&lt;br ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id  stars                                            reviews\n",
       "0  A2XP9IN4JOMROD      1  I wanted to love this. I was even prepared for...\n",
       "1  A2TS09JCXNV1VD      5  Grove Square Cappuccino Cups were excellent. T...\n",
       "2   AJ3L5J7GN09SV      2  I bought the Grove Square hazelnut cappuccino ...\n",
       "3  A3CZD34ZTUJME7      1  I love my Keurig, and I love most of the Keuri...\n",
       "4   AWKN396SHAQGP      1  It's a powdered drink. No filter in k-cup.<br ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../data/coffee.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Determine how many reviews there are in total.\n",
    "* Determine the percent of 1, 2, 3, 4 and 5 star reviews.\n",
    "* Create a new data set for modeling with the following columns:\n",
    "     - Column 1: 'positive' if review = 4 or 5, and 'negative' if review = 1 or 2\n",
    "     - Column 2: review text\n",
    "* Take a look at the number of positive and negative reviews in the newly created data set.\n",
    "\n",
    "Checkpoint: the resulting data set should have 514 reviews.\n",
    "\n",
    "Use the preprocessing code below to clean the reviews data before moving on to modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of reviews is 542\n"
     ]
    }
   ],
   "source": [
    "print('The number of reviews is',data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stars\n",
       "1     96\n",
       "2     45\n",
       "3     28\n",
       "4     65\n",
       "5    308\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data.groupby('stars').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2XP9IN4JOMROD</td>\n",
       "      <td>1</td>\n",
       "      <td>I wanted love I even prepared somewhat like ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2TS09JCXNV1VD</td>\n",
       "      <td>5</td>\n",
       "      <td>Grove Square Cappuccino Cups excellent Tasted ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AJ3L5J7GN09SV</td>\n",
       "      <td>2</td>\n",
       "      <td>I bought Grove Square hazelnut cappuccino k cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A3CZD34ZTUJME7</td>\n",
       "      <td>1</td>\n",
       "      <td>I love Keurig I love Keurig coffees This insta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AWKN396SHAQGP</td>\n",
       "      <td>1</td>\n",
       "      <td>It powdered drink No filter k cup br Just buy ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id  stars                                            reviews\n",
       "0  A2XP9IN4JOMROD      1  I wanted love I even prepared somewhat like ch...\n",
       "1  A2TS09JCXNV1VD      5  Grove Square Cappuccino Cups excellent Tasted ...\n",
       "2   AJ3L5J7GN09SV      2  I bought Grove Square hazelnut cappuccino k cu...\n",
       "3  A3CZD34ZTUJME7      1  I love Keurig I love Keurig coffees This insta...\n",
       "4   AWKN396SHAQGP      1  It powdered drink No filter k cup br Just buy ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords_english = set(stopwords.words('english'))\n",
    "data.loc[:,\"reviews\"] = data.reviews.apply(lambda x:\" \".join(re.findall('[\\w]+',x)))\n",
    "def remove_stopwords(s):\n",
    "    s = \" \".join(word for word in s.split() if word not in stopwords_english)\n",
    "    return s\n",
    "data.loc[:,\"reviews\"] = data.reviews.apply(lambda x:remove_stopwords(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(514, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(data.shape[0]):\n",
    "    if data.loc[i,'stars']==1 or data.loc[i,'stars']==2:\n",
    "        data.loc[i,'reviews_text'] = 'negative'\n",
    "    elif data.loc[i,'stars']==4 or data.loc[i,'stars']==5:\n",
    "        data.loc[i,'reviews_text'] = 'positive'\n",
    "data_trim = data[data.reviews_text.apply(lambda x:x=='positive' or x=='negative')]\n",
    "data_trim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>reviews</th>\n",
       "      <th>reviews_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2XP9IN4JOMROD</td>\n",
       "      <td>1</td>\n",
       "      <td>I wanted love I even prepared somewhat like ch...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2TS09JCXNV1VD</td>\n",
       "      <td>5</td>\n",
       "      <td>Grove Square Cappuccino Cups excellent Tasted ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AJ3L5J7GN09SV</td>\n",
       "      <td>2</td>\n",
       "      <td>I bought Grove Square hazelnut cappuccino k cu...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A3CZD34ZTUJME7</td>\n",
       "      <td>1</td>\n",
       "      <td>I love Keurig I love Keurig coffees This insta...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AWKN396SHAQGP</td>\n",
       "      <td>1</td>\n",
       "      <td>It powdered drink No filter k cup br Just buy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id  stars                                            reviews  \\\n",
       "0  A2XP9IN4JOMROD      1  I wanted love I even prepared somewhat like ch...   \n",
       "1  A2TS09JCXNV1VD      5  Grove Square Cappuccino Cups excellent Tasted ...   \n",
       "2   AJ3L5J7GN09SV      2  I bought Grove Square hazelnut cappuccino k cu...   \n",
       "3  A3CZD34ZTUJME7      1  I love Keurig I love Keurig coffees This insta...   \n",
       "4   AWKN396SHAQGP      1  It powdered drink No filter k cup br Just buy ...   \n",
       "\n",
       "  reviews_text  \n",
       "0     negative  \n",
       "1     positive  \n",
       "2     negative  \n",
       "3     negative  \n",
       "4     negative  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_trim.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Prepare the data for modeling:\n",
    "* Split the data into training and test sets. You should have four sets of data - X_train, X_test, y_train, y_test\n",
    "\n",
    "Create numerical features with Count Vectorizer. Create two document-term matrices:\n",
    "* Matrix 1: Terms should be unigrams (single words), and values should be word counts (Hint: this is the Count Vectorizer default)\n",
    "* Matrix 2: Terms should be unigrams and bigrams, and values should be binary values\n",
    "\n",
    "Recommendation: Utilize Count Vectorizer's stop words function to remove stop words from the reviews text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data_trim.loc[:,'reviews']\n",
    "y = data_trim.loc[:,'reviews_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest = train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "xtrain_cv = cv.fit_transform(xtrain).toarray()\n",
    "xtest_cv = cv.transform(xtest).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "lr = LogisticRegression(solver='lbfgs')\n",
    "lr.fit(xtrain_cv,ytrain)\n",
    "y_pred = lr.predict(xtest_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ngrams(text,n=2):\n",
    "    tokens = text.lower().split()\n",
    "    return list(ngrams(tokens,n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [build_ngrams(document) for document in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('i', 'wanted'),\n",
       "  ('wanted', 'love'),\n",
       "  ('love', 'i'),\n",
       "  ('i', 'even'),\n",
       "  ('even', 'prepared'),\n",
       "  ('prepared', 'somewhat'),\n",
       "  ('somewhat', 'like'),\n",
       "  ('like', 'cheap'),\n",
       "  ('cheap', 'circle'),\n",
       "  ('circle', 'k'),\n",
       "  ('k', 'cappuccino'),\n",
       "  ('cappuccino', 'unfortunately'),\n",
       "  ('unfortunately', 'product'),\n",
       "  ('product', 'really'),\n",
       "  ('really', 'greasy'),\n",
       "  ('greasy', 'you'),\n",
       "  ('you', 'actually'),\n",
       "  ('actually', 'see'),\n",
       "  ('see', 'grease'),\n",
       "  ('grease', 'cup'),\n",
       "  ('cup', 'it'),\n",
       "  ('it', '80'),\n",
       "  ('80', 'calories'),\n",
       "  ('calories', 'per'),\n",
       "  ('per', 'serving'),\n",
       "  ('serving', 'taste'),\n",
       "  ('taste', 'really'),\n",
       "  ('really', 'really'),\n",
       "  ('really', 'powder'),\n",
       "  ('powder', 'tasting'),\n",
       "  ('tasting', 'like'),\n",
       "  ('like', 'powdered'),\n",
       "  ('powdered', 'milk'),\n",
       "  ('milk', 'i'),\n",
       "  ('i', 'expecting'),\n",
       "  ('expecting', 'starbucks'),\n",
       "  ('starbucks', 'cap'),\n",
       "  ('cap', 'k'),\n",
       "  ('k', 'cup'),\n",
       "  ('cup', 'i'),\n",
       "  ('i', 'expecting'),\n",
       "  ('expecting', 'little'),\n",
       "  ('little', 'br'),\n",
       "  ('br', 'br'),\n",
       "  ('br', 'i'),\n",
       "  ('i', 'read'),\n",
       "  ('read', 'reviews'),\n",
       "  ('reviews', 'sort'),\n",
       "  ('sort', 'mixed'),\n",
       "  ('mixed', 'i'),\n",
       "  ('i', 'chose'),\n",
       "  ('chose', 'try'),\n",
       "  ('try', 'i'),\n",
       "  ('i', 'buy'),\n",
       "  ('buy', 'they'),\n",
       "  ('they', 'sit'),\n",
       "  ('sit', 'top'),\n",
       "  ('top', 'cupboard'),\n",
       "  ('cupboard', 'shelf'),\n",
       "  ('shelf', 'till'),\n",
       "  ('till', 'desperate'),\n",
       "  ('desperate', 'i'),\n",
       "  ('i', 'guess'),\n",
       "  ('guess', 'throw'),\n",
       "  ('throw', 'away'),\n",
       "  ('away', 'three'),\n",
       "  ('three', 'boxes'),\n",
       "  ('boxes', 'eesssh'),\n",
       "  ('eesssh', 'br'),\n",
       "  ('br', 'br'),\n",
       "  ('br', 'i'),\n",
       "  ('i', 'also'),\n",
       "  ('also', 'realize'),\n",
       "  ('realize', 'eligible'),\n",
       "  ('eligible', 'return'),\n",
       "  ('return', 'sucks'),\n",
       "  ('sucks', 'oh'),\n",
       "  ('oh', 'well'),\n",
       "  ('well', 'buyer'),\n",
       "  ('buyer', 'beware'),\n",
       "  ('beware', 'right')],\n",
       " [('grove', 'square'),\n",
       "  ('square', 'cappuccino'),\n",
       "  ('cappuccino', 'cups'),\n",
       "  ('cups', 'excellent'),\n",
       "  ('excellent', 'tasted'),\n",
       "  ('tasted', 'really'),\n",
       "  ('really', 'good'),\n",
       "  ('good', 'right'),\n",
       "  ('right', 'keurig'),\n",
       "  ('keurig', 'brewer'),\n",
       "  ('brewer', 'nothing'),\n",
       "  ('nothing', 'added'),\n",
       "  ('added', 'wwould'),\n",
       "  ('wwould', 'highly'),\n",
       "  ('highly', 'recommend'),\n",
       "  ('recommend', 'rccjr')],\n",
       " [('i', 'bought'),\n",
       "  ('bought', 'grove'),\n",
       "  ('grove', 'square'),\n",
       "  ('square', 'hazelnut'),\n",
       "  ('hazelnut', 'cappuccino'),\n",
       "  ('cappuccino', 'k'),\n",
       "  ('k', 'cups'),\n",
       "  ('cups', 'expecting'),\n",
       "  ('expecting', 'much'),\n",
       "  ('much', 'what'),\n",
       "  ('what', 'pleasant'),\n",
       "  ('pleasant', 'surprise'),\n",
       "  ('surprise', 'i'),\n",
       "  ('i', 'tasted'),\n",
       "  ('tasted', 'cup'),\n",
       "  ('cup', 'coffee'),\n",
       "  ('coffee', 'surprised'),\n",
       "  ('surprised', 'even'),\n",
       "  ('even', 'harsh'),\n",
       "  ('harsh', 'critic'),\n",
       "  ('critic', 'cappuccino'),\n",
       "  ('cappuccino', 'it'),\n",
       "  ('it', 'compared'),\n",
       "  ('compared', 'expensive'),\n",
       "  ('expensive', 'cappuccino'),\n",
       "  ('cappuccino', 'i'),\n",
       "  ('i', 'buy'),\n",
       "  ('buy', 'specialty'),\n",
       "  ('specialty', 'coffee'),\n",
       "  ('coffee', 'shops'),\n",
       "  ('shops', 'around'),\n",
       "  ('around', 'town'),\n",
       "  ('town', 'hey'),\n",
       "  ('hey', 'send'),\n",
       "  ('send', 'i'),\n",
       "  ('i', 'got'),\n",
       "  ('got', 'guests'),\n",
       "  ('guests', 'coming'),\n",
       "  ('coming', 'want'),\n",
       "  ('want', 'impress')]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(analyzer=lambda x:x)\n",
    "x = count_vect.fit_transform(corpus).toarray()\n",
    "data_ngram = pd.DataFrame(x,columns=count_vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(0, 42)</th>\n",
       "      <th>(00, i)</th>\n",
       "      <th>(00, k)</th>\n",
       "      <th>(0g, fiber)</th>\n",
       "      <th>(0g, protein)</th>\n",
       "      <th>(1, 10)</th>\n",
       "      <th>(1, 2)</th>\n",
       "      <th>(1, 20)</th>\n",
       "      <th>(1, 3)</th>\n",
       "      <th>(1, 30)</th>\n",
       "      <th>...</th>\n",
       "      <th>(yummy, must)</th>\n",
       "      <th>(yummy, perfect)</th>\n",
       "      <th>(yummy, real)</th>\n",
       "      <th>(yummy, strong)</th>\n",
       "      <th>(yummy, suitable)</th>\n",
       "      <th>(yummy, they)</th>\n",
       "      <th>(yummy, though)</th>\n",
       "      <th>(yummy, treat)</th>\n",
       "      <th>(yummy, you)</th>\n",
       "      <th>(yup, exactly)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10789 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   (0, 42)  (00, i)  (00, k)  (0g, fiber)  (0g, protein)  (1, 10)  (1, 2)  \\\n",
       "0        0        0        0            0              0        0       0   \n",
       "1        0        0        0            0              0        0       0   \n",
       "2        0        0        0            0              0        0       0   \n",
       "3        0        0        0            0              0        0       0   \n",
       "4        0        0        0            0              0        0       0   \n",
       "\n",
       "   (1, 20)  (1, 3)  (1, 30)  ...  (yummy, must)  (yummy, perfect)  \\\n",
       "0        0       0        0  ...              0                 0   \n",
       "1        0       0        0  ...              0                 0   \n",
       "2        0       0        0  ...              0                 0   \n",
       "3        0       0        0  ...              0                 0   \n",
       "4        0       0        0  ...              0                 0   \n",
       "\n",
       "   (yummy, real)  (yummy, strong)  (yummy, suitable)  (yummy, they)  \\\n",
       "0              0                0                  0              0   \n",
       "1              0                0                  0              0   \n",
       "2              0                0                  0              0   \n",
       "3              0                0                  0              0   \n",
       "4              0                0                  0              0   \n",
       "\n",
       "   (yummy, though)  (yummy, treat)  (yummy, you)  (yup, exactly)  \n",
       "0                0               0             0               0  \n",
       "1                0               0             0               0  \n",
       "2                0               0             0               0  \n",
       "3                0               0             0               0  \n",
       "4                0               0             0               0  \n",
       "\n",
       "[5 rows x 10789 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ngram.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(542, 10789)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ngram.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Logistic Regression to classify reviews as positive or negative. Do this for both matrices.\n",
    "* Fit a Logistic Regression model on the training data\n",
    "* Apply the model on the test data and calculate the following error metrics: accuracy, precision, recall, F1 score\n",
    "* Optional: Visualize the confusion matrix for both models\n",
    "* Compare the error metrics of the two matrices\n",
    "\n",
    "Recommendation: Create a function to calculate the error metrics, since you'll be doing this multiple times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's try using another machine learning technique to classify these reviews as positive or negative. Go through the exact same exercise in the previous step, except this time, use Naive Bayes instead of Logistic Regression.\n",
    "\n",
    "For count data, use [Multinomial Naive Bayes](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB). For binary data, use [Bernoulli Naive Bayes](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html#sklearn.naive_bayes.BernoulliNB).\n",
    "\n",
    "Compare the results of both the Logistic Regression and Naive Bayes models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5 ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up to this point, we've been using Count Vectorizer to create document-term matrices to input into the models. For at least one of the four models you've created so far, use TF-IDF Vectorizer instead of Count Vectorizer, and see if it improves the results.\n",
    "\n",
    "Out of all of the models you've created, which model do you think best classifies positive and negative cappuccino cup reviews?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "120px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
