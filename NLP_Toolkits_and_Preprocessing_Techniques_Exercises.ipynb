{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Toolkits and Preprocessing Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using [review data from Kaggle](https://www.kaggle.com/snap/amazon-fine-food-reviews) to practice preprocessing text data. The dataset contains user reviews for many products, but today we'll be focusing on the product in the dataset that had the most reviews - an oatmeal cookie. \n",
    "\n",
    "The following code will help you load in the data. If this is your first time using nltk, you'll to need to pip install it first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A368Z46FIKHSEZ</td>\n",
       "      <td>5</td>\n",
       "      <td>I love these cookies!  Not only are they healt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1JAPP1CXRG57A</td>\n",
       "      <td>5</td>\n",
       "      <td>Quaker Soft Baked Oatmeal Cookies with raisins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2Z9JNXPIEL2B9</td>\n",
       "      <td>5</td>\n",
       "      <td>I am usually not a huge fan of oatmeal cookies...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A31CYJQO3FL586</td>\n",
       "      <td>5</td>\n",
       "      <td>I participated in a product review that includ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A2KXQ2EKFF3K2G</td>\n",
       "      <td>5</td>\n",
       "      <td>My kids loved these. I was very pleased to giv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id  stars                                            reviews\n",
       "0  A368Z46FIKHSEZ      5  I love these cookies!  Not only are they healt...\n",
       "1  A1JAPP1CXRG57A      5  Quaker Soft Baked Oatmeal Cookies with raisins...\n",
       "2  A2Z9JNXPIEL2B9      5  I am usually not a huge fan of oatmeal cookies...\n",
       "3  A31CYJQO3FL586      5  I participated in a product review that includ...\n",
       "4  A2KXQ2EKFF3K2G      5  My kids loved these. I was very pleased to giv..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../data/cookie_reviews.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I participated in a product review that included a sample of <a href=\"http://www.amazon.com/gp/product/B007JFMH8M\">Quaker Soft Baked Oatmeal Cookie, Raisins, 8.8-Ounce (Pack of 12)</a>.  Okay first of all I love Oatmeal Raisin cookies and this one was no exception.  It was great!!! Soft n chewy, nice portion size and and as always a high quality product from Quaker Oats.  Thanks to Quaker and Influenster to for including this in their Mom Voxbox.  If you haven\\'t tried it you need to and make sure to share it with the family.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['reviews'][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Determine how many reviews there are in total.\n",
    "* Determine the percent of 1, 2, 3, 4 and 5 star reviews.\n",
    "* Determine the distribution of character lengths for the reviews, by listing the values and by plotting a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 913 rows and 3 coloumns \n"
     ]
    }
   ],
   "source": [
    "print('There are {} rows and {} coloumns '.format(data.shape[0],data.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stars\n",
      "1      4\n",
      "2     12\n",
      "3     56\n",
      "4    217\n",
      "5    624\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data_stars = (data.groupby('stars').size())\n",
    "print(data_stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "913\n"
     ]
    }
   ],
   "source": [
    "char_length = []\n",
    "for i in range(data.shape[0]):\n",
    "    char_length.append(len(data.loc[i,'reviews']))\n",
    "print(len(char_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(char_length,bins = 10,range = [0,2000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* Apply the following preprocessing steps:\n",
    "\n",
    "     1. Remove all words that contain numbers\n",
    "     2. Make all the text lowercase\n",
    "     3. Remove punctuation\n",
    "     4. Tokenize the reviews into words\n",
    "     \n",
    "  Hint #1: Use regular expressions.\n",
    "  \n",
    "  Hint #2: The cookie review in the second row has numbers, upper case letters and punctuation. You can use it to test out your regular expressions.\n",
    "     \n",
    "     \n",
    "* Find the most common words.\n",
    "* Determine the word length distribution over the entire corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I love these cookies!  Not only are they healthy but they taste great and are so soft!  I will definitely add these to my grocery list!'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[0,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:,\"reviews\"] = data.reviews.apply(lambda x : str.lower(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:,\"reviews\"] = data.reviews.apply(lambda x : \" \".join(re.findall('[\\w]+',x))) #removing punctuations and numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords_english = set(stopwords.words('english'))\n",
    "def remove_stopWords(s):\n",
    "    '''For removing stop words\n",
    "    '''\n",
    "    s = ' '.join(word for word in s.split() if word not in stopwords_english)\n",
    "    return s\n",
    "\n",
    "data.loc[:,\"reviews\"] = data.reviews.apply(lambda x: remove_stopWords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A368Z46FIKHSEZ</td>\n",
       "      <td>5</td>\n",
       "      <td>love cookies healthy taste great soft definite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1JAPP1CXRG57A</td>\n",
       "      <td>5</td>\n",
       "      <td>quaker soft baked oatmeal cookies raisins deli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2Z9JNXPIEL2B9</td>\n",
       "      <td>5</td>\n",
       "      <td>usually huge fan oatmeal cookies literally mel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A31CYJQO3FL586</td>\n",
       "      <td>5</td>\n",
       "      <td>participated product review included sample hr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A2KXQ2EKFF3K2G</td>\n",
       "      <td>5</td>\n",
       "      <td>kids loved pleased give kids quick go healthy ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id  stars                                            reviews\n",
       "0  A368Z46FIKHSEZ      5  love cookies healthy taste great soft definite...\n",
       "1  A1JAPP1CXRG57A      5  quaker soft baked oatmeal cookies raisins deli...\n",
       "2  A2Z9JNXPIEL2B9      5  usually huge fan oatmeal cookies literally mel...\n",
       "3  A31CYJQO3FL586      5  participated product review included sample hr...\n",
       "4  A2KXQ2EKFF3K2G      5  kids loved pleased give kids quick go healthy ..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Apply the following preprocessing techniques:\n",
    "\n",
    "\n",
    "     * Perform parts of speech tagging\n",
    "     * Perform stemming\n",
    "     * Optional: Perform lemmatization\n",
    "\n",
    "  Recommendation: Create a new column in your data set for every preprocessing technique you apply, so you can see the progression of the reviews text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>reviews</th>\n",
       "      <th>stemming</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A368Z46FIKHSEZ</td>\n",
       "      <td>5</td>\n",
       "      <td>love cookies healthy taste great soft definite...</td>\n",
       "      <td>love cookies healthy taste great soft definite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1JAPP1CXRG57A</td>\n",
       "      <td>5</td>\n",
       "      <td>quaker soft baked oatmeal cookies raisins deli...</td>\n",
       "      <td>quaker soft baked oatmeal cookies raisins deli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2Z9JNXPIEL2B9</td>\n",
       "      <td>5</td>\n",
       "      <td>usually huge fan oatmeal cookies literally mel...</td>\n",
       "      <td>usually huge fan oatmeal cookies literally mel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A31CYJQO3FL586</td>\n",
       "      <td>5</td>\n",
       "      <td>participated product review included sample hr...</td>\n",
       "      <td>participated product review included sample hr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A2KXQ2EKFF3K2G</td>\n",
       "      <td>5</td>\n",
       "      <td>kids loved pleased give kids quick go healthy ...</td>\n",
       "      <td>kids loved pleased give kids quick go healthy ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id  stars                                            reviews  \\\n",
       "0  A368Z46FIKHSEZ      5  love cookies healthy taste great soft definite...   \n",
       "1  A1JAPP1CXRG57A      5  quaker soft baked oatmeal cookies raisins deli...   \n",
       "2  A2Z9JNXPIEL2B9      5  usually huge fan oatmeal cookies literally mel...   \n",
       "3  A31CYJQO3FL586      5  participated product review included sample hr...   \n",
       "4  A2KXQ2EKFF3K2G      5  kids loved pleased give kids quick go healthy ...   \n",
       "\n",
       "                                            stemming  \n",
       "0  love cookies healthy taste great soft definite...  \n",
       "1  quaker soft baked oatmeal cookies raisins deli...  \n",
       "2  usually huge fan oatmeal cookies literally mel...  \n",
       "3  participated product review included sample hr...  \n",
       "4  kids loved pleased give kids quick go healthy ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "stemmer = LancasterStemmer()\n",
    "data.loc[:,\"stemming\"] = data.reviews.apply(lambda x:stemmer.stem(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>reviews</th>\n",
       "      <th>stemming</th>\n",
       "      <th>lemmatizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A368Z46FIKHSEZ</td>\n",
       "      <td>5</td>\n",
       "      <td>love cookies healthy taste great soft definite...</td>\n",
       "      <td>love cookies healthy taste great soft definite...</td>\n",
       "      <td>love cookies healthy taste great soft definite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1JAPP1CXRG57A</td>\n",
       "      <td>5</td>\n",
       "      <td>quaker soft baked oatmeal cookies raisins deli...</td>\n",
       "      <td>quaker soft baked oatmeal cookies raisins deli...</td>\n",
       "      <td>quaker soft baked oatmeal cookies raisins deli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2Z9JNXPIEL2B9</td>\n",
       "      <td>5</td>\n",
       "      <td>usually huge fan oatmeal cookies literally mel...</td>\n",
       "      <td>usually huge fan oatmeal cookies literally mel...</td>\n",
       "      <td>usually huge fan oatmeal cookies literally mel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A31CYJQO3FL586</td>\n",
       "      <td>5</td>\n",
       "      <td>participated product review included sample hr...</td>\n",
       "      <td>participated product review included sample hr...</td>\n",
       "      <td>participated product review included sample hr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A2KXQ2EKFF3K2G</td>\n",
       "      <td>5</td>\n",
       "      <td>kids loved pleased give kids quick go healthy ...</td>\n",
       "      <td>kids loved pleased give kids quick go healthy ...</td>\n",
       "      <td>kids loved pleased give kids quick go healthy ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id  stars                                            reviews  \\\n",
       "0  A368Z46FIKHSEZ      5  love cookies healthy taste great soft definite...   \n",
       "1  A1JAPP1CXRG57A      5  quaker soft baked oatmeal cookies raisins deli...   \n",
       "2  A2Z9JNXPIEL2B9      5  usually huge fan oatmeal cookies literally mel...   \n",
       "3  A31CYJQO3FL586      5  participated product review included sample hr...   \n",
       "4  A2KXQ2EKFF3K2G      5  kids loved pleased give kids quick go healthy ...   \n",
       "\n",
       "                                            stemming  \\\n",
       "0  love cookies healthy taste great soft definite...   \n",
       "1  quaker soft baked oatmeal cookies raisins deli...   \n",
       "2  usually huge fan oatmeal cookies literally mel...   \n",
       "3  participated product review included sample hr...   \n",
       "4  kids loved pleased give kids quick go healthy ...   \n",
       "\n",
       "                                          lemmatizer  \n",
       "0  love cookies healthy taste great soft definite...  \n",
       "1  quaker soft baked oatmeal cookies raisins deli...  \n",
       "2  usually huge fan oatmeal cookies literally mel...  \n",
       "3  participated product review included sample hr...  \n",
       "4  kids loved pleased give kids quick go healthy ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "data.loc[:,\"lemmatizer\"] = data.reviews.apply(lambda x:lemmatizer.lemmatize(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>reviews</th>\n",
       "      <th>stemming</th>\n",
       "      <th>lemmatizer</th>\n",
       "      <th>pos_tagging</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A368Z46FIKHSEZ</td>\n",
       "      <td>5</td>\n",
       "      <td>love cookies healthy taste great soft definite...</td>\n",
       "      <td>love cookies healthy taste great soft definite...</td>\n",
       "      <td>love cookies healthy taste great soft definite...</td>\n",
       "      <td>[(love, VB), (cookies, NNS), (healthy, JJ), (t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1JAPP1CXRG57A</td>\n",
       "      <td>5</td>\n",
       "      <td>quaker soft baked oatmeal cookies raisins deli...</td>\n",
       "      <td>quaker soft baked oatmeal cookies raisins deli...</td>\n",
       "      <td>quaker soft baked oatmeal cookies raisins deli...</td>\n",
       "      <td>[(quaker, NN), (soft, JJ), (baked, VBD), (oatm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2Z9JNXPIEL2B9</td>\n",
       "      <td>5</td>\n",
       "      <td>usually huge fan oatmeal cookies literally mel...</td>\n",
       "      <td>usually huge fan oatmeal cookies literally mel...</td>\n",
       "      <td>usually huge fan oatmeal cookies literally mel...</td>\n",
       "      <td>[(usually, RB), (huge, JJ), (fan, NN), (oatmea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A31CYJQO3FL586</td>\n",
       "      <td>5</td>\n",
       "      <td>participated product review included sample hr...</td>\n",
       "      <td>participated product review included sample hr...</td>\n",
       "      <td>participated product review included sample hr...</td>\n",
       "      <td>[(participated, JJ), (product, NN), (review, N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A2KXQ2EKFF3K2G</td>\n",
       "      <td>5</td>\n",
       "      <td>kids loved pleased give kids quick go healthy ...</td>\n",
       "      <td>kids loved pleased give kids quick go healthy ...</td>\n",
       "      <td>kids loved pleased give kids quick go healthy ...</td>\n",
       "      <td>[(kids, NNS), (loved, VBD), (pleased, JJ), (gi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id  stars                                            reviews  \\\n",
       "0  A368Z46FIKHSEZ      5  love cookies healthy taste great soft definite...   \n",
       "1  A1JAPP1CXRG57A      5  quaker soft baked oatmeal cookies raisins deli...   \n",
       "2  A2Z9JNXPIEL2B9      5  usually huge fan oatmeal cookies literally mel...   \n",
       "3  A31CYJQO3FL586      5  participated product review included sample hr...   \n",
       "4  A2KXQ2EKFF3K2G      5  kids loved pleased give kids quick go healthy ...   \n",
       "\n",
       "                                            stemming  \\\n",
       "0  love cookies healthy taste great soft definite...   \n",
       "1  quaker soft baked oatmeal cookies raisins deli...   \n",
       "2  usually huge fan oatmeal cookies literally mel...   \n",
       "3  participated product review included sample hr...   \n",
       "4  kids loved pleased give kids quick go healthy ...   \n",
       "\n",
       "                                          lemmatizer  \\\n",
       "0  love cookies healthy taste great soft definite...   \n",
       "1  quaker soft baked oatmeal cookies raisins deli...   \n",
       "2  usually huge fan oatmeal cookies literally mel...   \n",
       "3  participated product review included sample hr...   \n",
       "4  kids loved pleased give kids quick go healthy ...   \n",
       "\n",
       "                                         pos_tagging  \n",
       "0  [(love, VB), (cookies, NNS), (healthy, JJ), (t...  \n",
       "1  [(quaker, NN), (soft, JJ), (baked, VBD), (oatm...  \n",
       "2  [(usually, RB), (huge, JJ), (fan, NN), (oatmea...  \n",
       "3  [(participated, JJ), (product, NN), (review, N...  \n",
       "4  [(kids, NNS), (loved, VBD), (pleased, JJ), (gi...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "data.loc[:,'pos_tagging'] = data.reviews.apply(lambda x:pos_tag(word_tokenize(x)))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>reviews</th>\n",
       "      <th>stemming</th>\n",
       "      <th>lemmatizer</th>\n",
       "      <th>pos_tagging</th>\n",
       "      <th>ner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A368Z46FIKHSEZ</td>\n",
       "      <td>5</td>\n",
       "      <td>love cookies healthy taste great soft definite...</td>\n",
       "      <td>love cookies healthy taste great soft definite...</td>\n",
       "      <td>love cookies healthy taste great soft definite...</td>\n",
       "      <td>[(love, VB), (cookies, NNS), (healthy, JJ), (t...</td>\n",
       "      <td>[(love, VB), (cookies, NNS), (healthy, JJ), (t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1JAPP1CXRG57A</td>\n",
       "      <td>5</td>\n",
       "      <td>quaker soft baked oatmeal cookies raisins deli...</td>\n",
       "      <td>quaker soft baked oatmeal cookies raisins deli...</td>\n",
       "      <td>quaker soft baked oatmeal cookies raisins deli...</td>\n",
       "      <td>[(quaker, NN), (soft, JJ), (baked, VBD), (oatm...</td>\n",
       "      <td>[(quaker, NN), (soft, JJ), (baked, VBD), (oatm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2Z9JNXPIEL2B9</td>\n",
       "      <td>5</td>\n",
       "      <td>usually huge fan oatmeal cookies literally mel...</td>\n",
       "      <td>usually huge fan oatmeal cookies literally mel...</td>\n",
       "      <td>usually huge fan oatmeal cookies literally mel...</td>\n",
       "      <td>[(usually, RB), (huge, JJ), (fan, NN), (oatmea...</td>\n",
       "      <td>[(usually, RB), (huge, JJ), (fan, NN), (oatmea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A31CYJQO3FL586</td>\n",
       "      <td>5</td>\n",
       "      <td>participated product review included sample hr...</td>\n",
       "      <td>participated product review included sample hr...</td>\n",
       "      <td>participated product review included sample hr...</td>\n",
       "      <td>[(participated, JJ), (product, NN), (review, N...</td>\n",
       "      <td>[(participated, JJ), (product, NN), (review, N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A2KXQ2EKFF3K2G</td>\n",
       "      <td>5</td>\n",
       "      <td>kids loved pleased give kids quick go healthy ...</td>\n",
       "      <td>kids loved pleased give kids quick go healthy ...</td>\n",
       "      <td>kids loved pleased give kids quick go healthy ...</td>\n",
       "      <td>[(kids, NNS), (loved, VBD), (pleased, JJ), (gi...</td>\n",
       "      <td>[(kids, NNS), (loved, VBD), (pleased, JJ), (gi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id  stars                                            reviews  \\\n",
       "0  A368Z46FIKHSEZ      5  love cookies healthy taste great soft definite...   \n",
       "1  A1JAPP1CXRG57A      5  quaker soft baked oatmeal cookies raisins deli...   \n",
       "2  A2Z9JNXPIEL2B9      5  usually huge fan oatmeal cookies literally mel...   \n",
       "3  A31CYJQO3FL586      5  participated product review included sample hr...   \n",
       "4  A2KXQ2EKFF3K2G      5  kids loved pleased give kids quick go healthy ...   \n",
       "\n",
       "                                            stemming  \\\n",
       "0  love cookies healthy taste great soft definite...   \n",
       "1  quaker soft baked oatmeal cookies raisins deli...   \n",
       "2  usually huge fan oatmeal cookies literally mel...   \n",
       "3  participated product review included sample hr...   \n",
       "4  kids loved pleased give kids quick go healthy ...   \n",
       "\n",
       "                                          lemmatizer  \\\n",
       "0  love cookies healthy taste great soft definite...   \n",
       "1  quaker soft baked oatmeal cookies raisins deli...   \n",
       "2  usually huge fan oatmeal cookies literally mel...   \n",
       "3  participated product review included sample hr...   \n",
       "4  kids loved pleased give kids quick go healthy ...   \n",
       "\n",
       "                                         pos_tagging  \\\n",
       "0  [(love, VB), (cookies, NNS), (healthy, JJ), (t...   \n",
       "1  [(quaker, NN), (soft, JJ), (baked, VBD), (oatm...   \n",
       "2  [(usually, RB), (huge, JJ), (fan, NN), (oatmea...   \n",
       "3  [(participated, JJ), (product, NN), (review, N...   \n",
       "4  [(kids, NNS), (loved, VBD), (pleased, JJ), (gi...   \n",
       "\n",
       "                                                 ner  \n",
       "0  [(love, VB), (cookies, NNS), (healthy, JJ), (t...  \n",
       "1  [(quaker, NN), (soft, JJ), (baked, VBD), (oatm...  \n",
       "2  [(usually, RB), (huge, JJ), (fan, NN), (oatmea...  \n",
       "3  [(participated, JJ), (product, NN), (review, N...  \n",
       "4  [(kids, NNS), (loved, VBD), (pleased, JJ), (gi...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.chunk import ne_chunk\n",
    "data.loc[:,'ner'] = data.reviews.apply(lambda x:ne_chunk(pos_tag(word_tokenize(x))))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 6)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 8)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 0)\t1\n",
      "  (0, 1)\t1\n",
      "  (0, 2)\t1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "text = cv.fit_transform([\"Hi i am Abhinav Kumar jha learning the japanese language\"])\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abhinav</th>\n",
       "      <th>am</th>\n",
       "      <th>hi</th>\n",
       "      <th>japanese</th>\n",
       "      <th>jha</th>\n",
       "      <th>kumar</th>\n",
       "      <th>language</th>\n",
       "      <th>learning</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   abhinav  am  hi  japanese  jha  kumar  language  learning  the\n",
       "0        1   1   1         1    1      1         1         1    1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(text.toarray(), columns=cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entity drawing from tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_text = 'abhinav is living in united states and abhijeet is living in vadodara in national rail and transport institute'\n",
    "word_tokens = word_tokenize(my_text)\n",
    "word_tags = pos_tag(word_tokens)\n",
    "entity = ne_chunk(word_tags)\n",
    "entity.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compound Term extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['You_all', 'are', 'the', 'greatest', 'person', 'of_all_time']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import MWETokenizer\n",
    "mwetokenize = MWETokenizer([('You','all'),('of','all','time')])\n",
    "my_text = 'You all are the greatest person of all time'\n",
    "word_tokens = mwetokenize.tokenize(word_tokenize(my_text))\n",
    "print(word_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "48px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
